{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as io\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from lasso import RegularizationPathTrainTest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upvote data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load a text file of integers:\n",
    "y = np.loadtxt(\"yelp_data/upvote_labels.txt\", dtype=np.int)\n",
    "# Load a text file with strings identifying the 1000 features:\n",
    "featureNames = open(\"yelp_data/upvote_features.txt\").read().splitlines()\n",
    "# Load a csv of floats, which are the values of 1000 features (columns) for 6000 samples (rows):\n",
    "A = np.genfromtxt(\"yelp_data/upvote_data.csv\", delimiter=\",\")\n",
    "norms = np.apply_along_axis(np.linalg.norm,0,A)\n",
    "A = A / norms\n",
    "# print(np.apply_along_axis(np.linalg.norm,0,A))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Yelp Question in HW1, please normalize the data so that it has the same L2 norm. We will grade it either way, but please state clearly what you did to treat the yelp data, which is currently not normalized.\n",
    "\n",
    "http://stackoverflow.com/questions/7140738/numpy-divide-along-axis"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "toy = np.array([[0., 1, 100.], [1, 10., 1000]])\n",
    "print(toy)\n",
    "norms = np.apply_along_axis(np.linalg.norm,0,toy)  # np.linalg.norm assumes L2\n",
    "toy = toy / norms\n",
    "print(toy)\n",
    "# check the norms:\n",
    "np.apply_along_axis(np.linalg.norm,0,toy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_train = A[:4000, :]; y_train = y[:4000]\n",
    "A_val = A[4000:5000, :]; y_val = y[4000:5000]\n",
    "A_test = A[5000:, :]; y_test = y[5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models for varying lambda values.  Calculate training error for each model. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = RegularizationPathTrainTest(X_train=A_train[0:100, 0:50], y_train=y_train[0:100], lam_max=1, \n",
    "                                     X_val=A_val[0:100, 0:50], y_val=y_val[0:100,], steps=2, frac_decrease=0.05,\n",
    "                                    delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.analyze_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = RegularizationPathTrainTest(X_train=A_train, y_train=y_train, lam_max=10**4, \n",
    "                                     X_val=A_val, y_val=y_val, steps=10, frac_decrease=0.1, delta=0.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "started 9:07 PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result.analyze_path()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Star data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load a text file of integers:\n",
    "y = np.loadtxt(\"yelp_data/star_labels.txt\", dtype=np.int)\n",
    "# Load a text file with strings identifying the 2500 features:\n",
    "featureNames = open(\"yelp_data/star_features.txt\").read().splitlines()\n",
    "# Load a matrix market matrix with 45000 samples of 2500 features, convert it to csc format:\n",
    "A = sp.csc_matrix(io.mmread(\"yelp_data/star_data.mtx\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
